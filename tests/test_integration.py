#!/usr/bin/env python3
"""é›†æˆæµ‹è¯•è„šæœ¬ - æµ‹è¯•å®Œæ•´çš„ CLI å·¥ä½œæµç¨‹"""

import os
import sys
import json
import tempfile
from pathlib import Path

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from feedland_parser import Config, OPMLParser, FeedParser, ArticleExtractor, FeedTracker, Deduplicator, ParallelFeedProcessor


def test_cli_workflow():
    """æµ‹è¯•å®Œæ•´çš„ CLI å·¥ä½œæµç¨‹"""
    print("=" * 60)
    print("é›†æˆæµ‹è¯•: CLI å·¥ä½œæµç¨‹")
    print("=" * 60)

    # ä½¿ç”¨æµ‹è¯•é…ç½®æ–‡ä»¶
    test_config_path = Path(__file__).parent / "test_config.json"

    # 1. åŠ è½½é…ç½®
    print("\n1ï¸âƒ£ åŠ è½½é…ç½®...")
    config = Config(str(test_config_path))
    config.load()
    print(f"   âœ… é…ç½®åŠ è½½æˆåŠŸ: {config.url}")
    print(f"   âœ… çº¿ç¨‹æ•°: {config.threads}")

    # 2. è§£æ OPML
    print("\n2ï¸âƒ£ è§£æ OPML...")
    opml_parser = OPMLParser()
    feed_infos = opml_parser.parse_opml(config.url)
    print(f"   âœ… æ‰¾åˆ° {len(feed_infos)} ä¸ª feeds")

    if not feed_infos:
        print("   âš ï¸  æœªæ‰¾åˆ°ä»»ä½• feedsï¼Œæµ‹è¯•ç»ˆæ­¢")
        return False

    # 3. åˆå§‹åŒ–å¤„ç†å™¨
    print("\n3ï¸âƒ£ åˆå§‹åŒ–å¤„ç†å™¨...")
    article_extractor = ArticleExtractor()
    tracker = FeedTracker(config)
    tracker.load_history()
    deduplicator = Deduplicator(tracker)
    feed_parser = FeedParser(article_extractor, deduplicator, max_articles=2)  # åªæå– 2 ç¯‡ç”¨äºæµ‹è¯•
    print("   âœ… å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    # 4. å¹¶è¡Œå¤„ç†ï¼ˆé™åˆ¶æ•°é‡ä»¥åŠ å¿«æµ‹è¯•ï¼‰
    print("\n4ï¸âƒ£ å¹¶è¡Œå¤„ç† feedsï¼ˆé™åˆ¶ä¸º 2 ä¸ªç”¨äºæµ‹è¯•ï¼‰...")
    test_feeds = feed_infos[:2]  # åªæµ‹è¯•å‰ 2 ä¸ª feeds

    processor = ParallelFeedProcessor(feed_parser, tracker, max_workers=config.threads)

    results = processor.process_feeds_parallel(test_feeds)

    # 5. ç”Ÿæˆæ‘˜è¦
    summary = processor.get_summary(results)
    print(f"\n5ï¸âƒ£ å¤„ç†æ‘˜è¦:")
    print(f"   ğŸ“Š æ€» feeds: {summary['total_feeds']}")
    print(f"   âœ… æˆåŠŸ: {summary['successful_feeds']}")
    print(f"   âŒ å¤±è´¥: {summary['failed_feeds']}")
    print(f"   ğŸ“„ æ€»æ–‡ç« : {summary['total_articles']}")

    # 6. è·å–æˆåŠŸçš„ç»“æœ
    successful = processor.get_successful_results(results)
    if successful:
        print(f"\n6ï¸âƒ£ æˆåŠŸçš„ feeds:")
        for result in successful:
            print(f"   âœ… {result.feed_info.title}: {len(result.articles)} ç¯‡æ–‡ç« ")

    # 7. è·å–å¤±è´¥çš„ç»“æœ
    failed = processor.get_failed_results(results)
    if failed:
        print(f"\nâŒ å¤±è´¥çš„ feeds:")
        for result in failed:
            print(f"   âŒ {result.feed_info.title}: {result.error}")

    # 8. æµ‹è¯•è¾“å‡ºæ ¼å¼
    print(f"\n7ï¸âƒ£ æµ‹è¯•è¾“å‡ºæ ¼å¼...")
    output = processor.get_all_articles(results)
    if output:
        print(f"   âœ… è¾“å‡ºæ ¼å¼éªŒè¯é€šè¿‡ï¼Œå…± {len(output)} ç¯‡æ–‡ç« ")

        # æ˜¾ç¤ºç¬¬ä¸€ç¯‡æ–‡ç« çš„ä¿¡æ¯
        if output:
            article = output[0]
            print(f"\n   ğŸ“ ç¤ºä¾‹æ–‡ç« :")
            print(f"      æ ‡é¢˜: {article.get('title', 'Unknown')}")
            print(f"      URL: {article.get('url', 'Unknown')}")

    print("\n" + "=" * 60)
    print("âœ… é›†æˆæµ‹è¯•å®Œæˆï¼")
    print("=" * 60)

    return summary['successful_feeds'] > 0


if __name__ == "__main__":
    try:
        success = test_cli_workflow()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)