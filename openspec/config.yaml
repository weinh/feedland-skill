schema: spec-driven

# 项目上下文（可选）
# 这些信息会在创建文档时展示给 AI
# 添加技术栈、约定、风格指南、领域知识等
context: |
  技术栈：Python 3.11+、BeautifulSoup4、Newspaper3k、Feedparser
  依赖：requests、lxml、hashlib（用于去重）

  领域：RSS/Atom feed 内容提取和解析
  目的：从 RSS feed 中提取和清理文章内容，并进行去重

  关键需求：
  - 解析来自 Feedland 的 RSS/Atom feeds
  - 使用 Newspaper3k 提取主要内容，使用 BeautifulSoup 进行自定义解析
  - 实现去重功能，避免多次提取重复提取同一篇文章，已经提取的不再提取
  - 将提取的内容以结构化格式存储
  - 处理各种 feed 格式和边界情况

  去重策略：
  - feeds的URL作为主键，提取后记录被提取最新文章的时间，后续只提取更新的内容
  - 跟踪已处理的文章以避免重复处理

  代码风格：
  - 遵循 PEP 8 Python 代码规范
  - 在适当的地方使用类型提示
  - 为函数和类编写文档字符串
  - 包含网络和解析失败的错误处理

# 每个文档的规则（可选）
# 为特定文档添加自定义规则
rules:
  proposal:
    - 保持提案简洁且聚焦
    - 始终包含"非目标"部分以明确范围
    - 指定 feed 源和输出格式要求
  tasks:
    - 将任务分解为最大 2 小时的块
    - 为每个组件包含测试任务
    - 添加错误处理和边界情况的任务
  specs:
    - 明确定义 feed 解析、内容提取和去重的需求
    - 包含格式错误的 feed、网络错误和重复检测的场景
  design:
    - 清晰记录去重策略
    - 解释 BeautifulSoup 和 Newspaper3k 之间的集成
    - 包含提取过程的数据流图
